{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PS7QjJCs3Pfo"
      },
      "source": [
        "# 0. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gc7f-6ml3Pfv"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "# install required libraries\n",
        "# !pip3 install google-generativeai             # Google's Gemini API (no need to install in Colab)\n",
        "!pip3 install openai                            # OpenAI API\n",
        "!pip3 install tiktoken                          # Estimate costs of using OpenAI models\n",
        "!pip3 install ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "m3mujblBuJ7V"
      },
      "outputs": [],
      "source": [
        "# basic libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from IPython.core.display import HTML\n",
        "from tqdm import tqdm\n",
        "import urllib.request\n",
        "import re\n",
        "import tiktoken\n",
        "\n",
        "# LLMs APIs\n",
        "import google.generativeai as genai\n",
        "from openai import OpenAI\n",
        "\n",
        "# colab secrets\n",
        "\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSvDUgoeuJ7W"
      },
      "source": [
        "# 1. Interacting with LLMs through APIs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su0DdYUXWVWW"
      },
      "source": [
        "### What is an API?\n",
        "\n",
        "Application Programming Interfaces (APIs) allow applications to *speak to each other*. In our context, we will use APIs so that Python can directly speak to multiple language models. This will help us programatically interact with language models and fulfill certain tasks that can't be done manually.\n",
        "\n",
        "<br>\n",
        "\n",
        "*How would you summarize 10,000 different news articles using ChatGPT?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Eca56bJa9u_"
      },
      "source": [
        "### Requirements for using an API\n",
        "\n",
        "To interact with an API we just need to use a programming language supported by the API (most of them support Python) and a key that identifies us. In order to get started with an API, it is always a good idea to go to the documentation provided by its creator.\n",
        "\n",
        "- [Google](https://ai.google.dev/gemini-api)\n",
        "- [OpenAI](https://platform.openai.com/docs/quickstart?context=python)\n",
        "- [Anthropic](https://www.anthropic.com/api)\n",
        "\n",
        "\n",
        "Below, we will provide some boilerplate code to interact with some of the main APIs in the market."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VIHec60rbjAc"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "display(HTML(\"\"\"\n",
        "<div class=\"alert\">\n",
        "  <h2> APIs Keys </h2>\n",
        "  <br>\n",
        "  <p> Be careful! Never leave your keys in public repositories or in files that are shared. Since some of the API services are paid, this can lead to malicious actors using your key. </p>\n",
        "\n",
        "</div>\n",
        "\n",
        "<style>\n",
        ".alert {\n",
        "  padding: 20px;\n",
        "  background-color: #D72638;\n",
        "  color: white;\n",
        "  margin-bottom: 15px;\n",
        "}\n",
        "\n",
        "h2{\n",
        "  font-size: 30px;\n",
        "  color: white;\n",
        "}\n",
        "\n",
        "li, p{\n",
        "  font-size: 20px;\n",
        "}\n",
        "\n",
        "</style>\n",
        "\"\"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9qsNVFrSMbs"
      },
      "source": [
        "### Some key parameters for text generation with LLMs\n",
        "\n",
        "- [Temperature](https://lukesalamone.github.io/posts/what-is-temperature/): Controls the \"randomness\" of the generated text by influencing the underlying token probabilities.\n",
        "- Max tokens: Helps you pre-define the number of tokens that the model generates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns22h13rzVs9"
      },
      "source": [
        "## Google"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ybDrpAqWZSM"
      },
      "outputs": [],
      "source": [
        "# load the key from secret manager\n",
        "\n",
        "api_key = userdata.get(\"gem_key\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbdVyL_QuJ7X"
      },
      "outputs": [],
      "source": [
        "# add your key to the API configuration\n",
        "genai.configure(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKAjb3T3da1V"
      },
      "outputs": [],
      "source": [
        "# Set up the model\n",
        "generation_config = {\n",
        "\"temperature\": 0.8,             # Controls the randomness of the output - temperature = 1 - use original distribution.\n",
        "\"max_output_tokens\": 150,       # The maximum number of tokens to include - the length of the content in the result\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hy4rY2DEI7Wm"
      },
      "outputs": [],
      "source": [
        "models = genai.list_models()\n",
        "\n",
        "# Print out each model's name and capabilities\n",
        "for model in models:\n",
        "    print(f\"Model name: {model.name}\")\n",
        "    print(f\"  Description: {model.description}\")\n",
        "    print(f\"  Supported methods: {model.supported_generation_methods}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GVIcoLAdRDJ"
      },
      "outputs": [],
      "source": [
        "# initialize the model\n",
        "model = genai.GenerativeModel(model_name='gemini-1.5-pro',            # name of the model we want to use\n",
        "                              generation_config=generation_config     # parameters\n",
        "                              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yklwzZdWT4xy"
      },
      "outputs": [],
      "source": [
        "# generate a response from a prompt\n",
        "result = model.generate_content(contents={'role':'user',\n",
        "                                          'parts': \"Write a short song about the housing market in London in the style of Skepta\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-sxbcIbT-pG"
      },
      "outputs": [],
      "source": [
        "# extract the text from the response object\n",
        "print(result.candidates[0].content.parts[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHbG0ToYzZfS"
      },
      "source": [
        "## OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOK59Nigd8th"
      },
      "outputs": [],
      "source": [
        "# load the key from secret manager\n",
        "\n",
        "api_key = userdata.get(\"openai_key\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDgMI47tuJ7X"
      },
      "outputs": [],
      "source": [
        "# initialize a client using the API key\n",
        "client = OpenAI(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRpg1jlUUw9s"
      },
      "outputs": [],
      "source": [
        "# get a response from the model\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-0125\",    # name of the model,\n",
        "    messages=[\n",
        "        {\"role\": \"user\",\n",
        "         \"content\": \"Explain the word2vec model with some verses in the style of Samuel Taylor Coleridge.\"}    # prompt\n",
        "    ],\n",
        "    max_tokens=100,                 # max number of tokens to be generate\n",
        "    temperature=0.1                 # controls the randomness of the output\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOoHUKGwVz-P"
      },
      "outputs": [],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig7TxJTOzfBH"
      },
      "source": [
        "## Anthropic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNqN3TwguJ7X"
      },
      "outputs": [],
      "source": [
        "!pip3 install anthropic\n",
        "\n",
        "from anthropic import Anthropic\n",
        "\n",
        "client = Anthropic(\n",
        "    api_key=\"ANTHROPIC_API_KEY\",\n",
        ")\n",
        "\n",
        "message = client.messages.create(\n",
        "    max_tokens=1024,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Hello, Claude\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"claude-3-opus-20240229\",\n",
        ")\n",
        "print(message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lTPqlWvzjIr"
      },
      "source": [
        "## Cohere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXTm_jFB0B4F"
      },
      "outputs": [],
      "source": [
        "!pip3 install cohere\n",
        "\n",
        "import cohere\n",
        "\n",
        "co = cohere.Client(\n",
        "    api_key=\"YOUR_API_KEY\",\n",
        ")\n",
        "\n",
        "chat = co.chat(\n",
        "    message=\"hello world!\",\n",
        "    model=\"command\"\n",
        ")\n",
        "\n",
        "print(chat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywZZNMrn0CvA"
      },
      "source": [
        "## Mistral AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_ffZIusVf_c"
      },
      "outputs": [],
      "source": [
        "!pip3 install mistralai\n",
        "\n",
        "from mistralai.client import MistralClient\n",
        "\n",
        "client = MistralClient(api_key=\"YOUR_KEY\")\n",
        "\n",
        "response = client.completion(\n",
        "    model=\"codestral-latest\",\n",
        "    prompt=\"Hi\",\n",
        ")\n",
        "\n",
        "response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJdUd3rxuJ7Y"
      },
      "source": [
        "# 2. Demonstrating different tasks with LLMs\n",
        "\n",
        "In order to get ourselves familiarized with how to effectively work with the API of modern LLMs, we will demonstrate two different tasks through the notebook.\n",
        "\n",
        "- **Task 1: Structuring unstructured data.** We will use a corpus of news articles from Colombia to extract from them some of the main actors involved in the events described.\n",
        "- **Task 2: Latent concept detection.** We will categorize sentences from press conferences after the Federal Open Market Committee (FOMC) as hawkish, neutral or dovish. We will compare the results obtained with an LLM with the labels provided by the authors of [The Voice of Monetary Policy](https://www.aeaweb.org/articles?id=10.1257/aer.20220129) and with a dictionary-based approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Swrq7rIn0hSk"
      },
      "source": [
        "### Creating an effective prompt\n",
        "\n",
        "There are many resources available online to get you started on how to build good prompts. I recommend you to search directly within the documentation of the builder of the LLM you want to use for the best advice on how to create prompts for that specific model. Here are some examples:\n",
        "\n",
        "- OpenAI:\n",
        "    - [Guide 1](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api)\n",
        "    - [Guide 2](https://platform.openai.com/docs/guides/prompt-engineering)\n",
        "    - [Cookbook](https://cookbook.openai.com/)\n",
        "- Anthropic\n",
        "    - [Guide](https://docs.anthropic.com/en/docs/prompt-engineering)\n",
        "    - [Cookbook](https://github.com/anthropics/anthropic-cookbook/)\n",
        "\n",
        "- Google\n",
        "    - [Guide](https://ai.google.dev/gemini-api/docs/prompting-intro)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsrIbMYiz6Fk"
      },
      "source": [
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZ4AAACuCAYAAAAGcWsWAAAgAElEQVR4Xu2dB3gc1bn3/7urXfXeiy25SXJvyDYdbEKooQQCBGNIwHApX0huHghwA8YJXJJ7gZub5/oaHEjAhJqQYBO4CTVAYtyb3G3Zsq3ee93yvbOj0c7OzuzMrlbWSno3D3lsz8yZc37nzPnPW84Zk4t+4N8AgX14bOHFWHvK6v77jWursO4GPTjd2Lv+Sfxk3UbsPtaKHgedb4vHpOlX4L6nf4LbF2dBLK0Cbz34PTz9f8dR1dwNp/BPdF7B9Atx+6M/x/3LMgfOEw7048Drd+OOxz/D0fZ+99Vpl67B0dev06sMH2cCTIAJhD0BEwtP2PcRV5AJMAEmMKYIsPCMqe7kxjABJsAEwp8AC0/49xHXkAkwASYwpgiw8Iyp7uTGMAEmwATCnwALT/j3EdeQCTABJjCmCLDwjKnu5MYwASbABMKfAAtP+PcR15AJMAEmMKYIsPCMqe7kxjABJsAEwp8AC0/49xHXkAkwASYwpgiw8Iyp7uTGMAEmwATCnwALT/j3EdeQCTABJjCmCLDwjKnu5MYwASbABMKfAAtP+PcR15AJMAEmMKYIsPCMqe7kxjABJsAEwp8AC0/49xHXkAkwASYwpgiw8Iyp7uTGMAEmwATCnwALT/j3EdeQCTABJjCmCLDwjKnu5MYwASbABMKfAAtP+PcR15AJMAEmMKYIsPCMqe7kxjABJsAEwp8AC0/49xHXkAkwASYwpgiw8Iyp7uTGMAEmwATCnwALT/j3EdeQCTABJjCmCLDwjKnu5MYwASbABMKfAAtP+PcR15AJMAEmMKYIsPCMqe7kxjABJsAEwp8AC0/49xHXkAkwASYwpgiw8Iyp7uTGMAEmwATCnwALT/j3EdeQCTABJjCmCLDwjKnu5MYwASbABMKfwBkRHkd/G0z0P5fDCrvTgj70wGKzw2XqgcvpBJwxiHDRf2YbzGbAHGEKf3JcQybABJgAEwiKwLAJj8vVT4LSjrLDX6G/ux2pGcVIzSqEyRwFs8WEbkcriYwLJpOFJCkaEYgC7ILgOOFykRiZnDBFCMcsQTWML2ICTIAJMIHwJBBy4elzdKG8/hM0V27H5Pip2HXgMMwxyZg8ZQFSkrORlJKNjq42WCLMsNmiAVcUCU2k2yIim4go9ZIgWdHndKHNVYmenm5kRk2F1RIZngS5VmFLoK3PhY1HHKjudKIwxYxrpkWEbV25YkxgPBEIqfBUte1HtWsnWmqOw9ZUi8iWDjijs5E8cQH6eiLgJJHJyy1AbX0dMjIykZSQATPiibeNxIesH3TDbOpEl70THT2dqOs+hbLTpSieOBkpUbORHl88nvqG2zpEArf+uQuVTWQ9D/yumGnFw0v4BWaIWPlyJjBkAiETniOnPwfiO2CJMcPc1wlL8zHUH/on4vMWY/L0q7Dv0DFkZ+YjyhaPpsZmWMiCSUmagGhbMv2ZhMckWDud6Ec96ppOob2/A629DSg7fgBzigvR2FiBrLT5KM761pAbzQWMTQKHGp14fksvjlQ7dBt44TQrfrzEhgQbxxN1YfEJTCDEBEIiPA5XA/684U1YIs04/8IFKN3xEZqrdqB4cirq+xIQkz4b2emFyEqeBKedsgdM9LD3k2PNGQlbRByJjhWwCPGeHnT0V6GxtQrkfYMpxoWK6mPobm9Ga2cteiy9mJ53MRZmXDdkDI4Ta3Fpyc+wk+piMp1FE9ZG3DFpyMVCKneXuWRIZeqXcwK/vnwBVm2PxiVPb8Ef7p7grnzfJz9C5i1vu/+ce/sb2PfsRUNvVIhLcOFjPJB6G96gTJL7367CU0tDc4OVH3ThaI3HwtEr9ab5Nty7wKZ3Gh9nAkwgxASGLDxHD+5GdLQJbU0N2LPnH0hLd5GYtCIqyonktCTsO12DymYnVtz8I3KoJSPanCw2wUFJBEJigYlccH0kQiYHLFYXep1N6OhrgNNKIuSqwrHTu1BddgrZOZOQnjUF+alzEOPKQ6QpcUgoDr1wKc5+fN9gGfLJeygF6wuGsdL1y/EVHvmEnrjo5/jygzsx0djthu0sqR1li58arM9wCc9FL3cE1I5pWWb85sqYgK7hk5kAExg6gSEJz/GD++Cg4L/F0o8DpZuw5Z9/xNJlc2EjyycxLQeTChfgdGcd2ux2FE24ANGWfLQ196KpppaSDSYigrLbXO6EAjP9P2WvUSZbv4NSrCPa0EuJBQerP8bxk1sQb0nGjIJLMDHjApj6kmAxx8JOgWNrHFlKQf08k3ZJyUJs27YDoZqo9QUjqAqrXOQrPB/8qwXLX8uktPQV+FPtL3B+qG41hHIkgZfzHSnhEYSmqw+DcR8WniF0LF/KBIZAIGjh2b71H9izbSsKJxWguqIUp078E0XFGZg9Zya6uq3IKZiLyMQ0VHccQ3RyPBIjKJXakYn33/sUjbW1+N7tNyOKhMPZ30tutkjKZLOhv98Op9OOiEgHGjsO42DFZyRA9chJKkB2yjzERc5BpCOWrKsO/PVPGzDz7PmYOXdWwM2XxGGv5Xa8vbkAT5eshtI1Jp8c73trMzKfnet2awk/b/eQRwCEY3c9tRo7/+2JwfJun+RxK9371uto/c4t+GDJ04Nv/5JYSI2QytYXMG/heX3y84MuNn/1E+4jdy3K2ymv3xcfTMR/DLjDtNvv3XZl2cq2CccFy/Kduw8NutrkZXvq5SlX7i6U3IiCiJWTNSf9hOy1ez/oIUHRju3kUlbb2iujcZjiQA992D14rRDrWX0BJxwE/BDxBUxgCASCEh5BHNa8+Evs2LoDZHtgUq4NZy+ehNjEaORMnIZkiufAlQREWOGIaESbs5GCuMWor+vFjq8PIScrEwsXzKSFovT6KVg7dhIghwlmq40mRSHW04fO3lpUtexDZJwJObFC8CWF3HHpaGtrw54tO2DqtWPWvPlIz8sJuPnSW7g4qeWrxkrkE7LyBh6Lwnfilc6VJlG58EjHpLf/0gELRVm+IByrJ4kxKO1YkefeS5/6GbIe+6k7ZuIb11Gvo9SG82TxFnn95MITaPulsttU2qcUHq2y0wdcoXLrTRIypVv0tX39eJmSCuS/JBo3LR2CNU2xrgHREf6sJlAvXBuD4lSKPfKPCTCBM0IgKOFxOTvx0u9ewsu/XYMkWw8euGsFoiMjcKCsDDesWIEUSpVua7EjLioeETHtaO6uJkdaOsVlMtBL80NqUhLtYNBFnjU7reeJdicZkH+NXsWBro5W2PsbYaVye2lNkM0ahaiITIIRSRLnQpejm7LiWjAhsxgRthjY6SXXFsAaUzU3jyRE8klOfp40mUtv3JKofLfME8iXrAypLDXhkbub1CwaaWIV7rfn/oOGhUcpdv6SJJTt//lSj0Wm5Q6T2i9PyFCLifljq1e2kq1csAW2Uj3ftCzySdr4j829+HA/LVge+C3It+D5S6LxxJc92FJuxx9ujnUf0bKKnrgkCkvzeY3PGZlx+CZMgAgELDzOnja0Vm/B519tR1lFJbZ8+RVuvO7b6CZFScrNwGXXX+ZOFOi397sXhEZFOMh91o3j5TUomryA/s2K9u4mxERGUSwims6jt1In7WZgjkRPF4kOreGJoC1zLBT/cVI53Z29MHVG0PEISrbugjXSTtV2oKPZDGtMDuLTMpEQTVvtmIy9sSonOGGSlk+okoCoTaJKsVjyNzFBQW1SlSZI5QQqZXApkxvkozFQ4ZFbPGrxHa17ySd0ZYaZ1H7vid43ruSvbKGtRmM8ekK887INbleiWqbee0f68auvPBZPFKVI/+qKaLcVU9nuQjy91/hzxb3+nVjkxnNaNc+ITOBMEQhYeBq+fg1Hdr+HrDkXoNWRiEOH65GQnIbMiRkwxdqROiGBrBjyslF6dEdnPVJiYhFBKcut7T0kc1bExSaQ0Dhpi5wIdPfYyepJgM2doUbrf8x2ypCjY9ZYsoKi4bTYSWJcMPdS/KePrCOrHZUn96C7tR6Zyfm0I0IaumyJsFojkZkiWEX6P7W4g3LSF1KQgxUe5QSqJzxaiQBDifGoxUWENirdXEMVHnlcSa3soQqPPBZ36/I1eHV9vGb6tdLqkYuPYPl8eVR4YfH+RVJuyr20oPTawmCTVPTHG5/BBJiAL4GAhefE67fCTpN9T+IEvP3p15h38QVIn5aBbQc+RdH0PCTGRuH4wZO4cOEyco7ZUN6wi9bm1KOoYB6qa6vISrHC1p0Ca3csCUY0MtOL4OxMRltXAwlYNOKS4inmY0dfVydMtkjawcBB2XBJiIlNon3ezNjxxQcUK6rEoiVL0OM0Ueq1A8kJ6ZRqPVm3f/3FbaSL1WIfWgF/ydUmD9b7c7XJg/7y9TZyt9XhF9eh7p67cc7AOiMjMR7permoKl1/au4yI8IjWEJS+UrLcPkR0eLTKlsuPFpuTP/JFN7xKb1sPWU6tSA+M7It2HnSV3SE/uasNt1Hhk9gAsNCICDhaTr+BVo2PUNCsxS/eOmPcObl4oqVV+HL0vfR0FGKi869CJZ2M9ItE5AfNxVHSw+hvGMLum2nkJNWCEtCDKra6pFhL0JR0jzk55Ofy56E3g6ykigF2xZPG4VSTAeOdrQ3n0AU7fEGUzystPbHRBaSyWFGQ3UFjpbtQ+aEbMp+s5BlZaUFpj2YXLiQ/i5mnWn91Nxs0rnKSVUe+9CaHNUSB6Ty1GI8etlmwrXS5BqM8MiFVbq/5A5UY2JUeJTXSq7FLsVaKPl5UlvlAqtldQkCpWXhBbIgltfxDMscwYUygZATCEh49r21GhFVGzHh0nvx+//7B8rsbbju3qtxsPxrNNeW4bIl1yAnOgeuBgdO7D+KIwd3YfK0BLTbq3CgvBTJ0+egiUIxSbSbQWxnPNrrgRKyjAryKcMtMpE2BrUhOiGB3G+UCdd0hOI2lFgQnYbo+CxKRiDhoQWnEfRf1WnazaC1ldxyNthio7Hn4AEsXrIMcdEpfgH9+vJkd0q0+pod7xTe0mf7fVbXq02Oyh0QfvnmVXjrplWq6dS+q/R9M86U1kMgFo/QePlELYrYPdg1sMOBIEbPbXkQ28+6dXDXADWBFcqRi5iUIi7s8uBtdXjqr1a2FM+SW2JaLjkt4dF3OXq6XMulpjUofng+u9lCPqNwgUzAAIGAhOefv7gCE9L7YSlYDEfeDBxqasTsJdNx+sQh2pHAhemUabb5w09x6vhJEhKbO9azaGY+mhrKUVp3DK3JlFgQa6V93Ghr0M4EZCdPg9kVi7SMAhRMnYH4hGTa8SCSrJ8+OPpq0VDbTBZPAjJzJsNOi0bbe2hxKSUxVFD2XJzZ5N65uqalCdFZqZgwuQj5SfkGmjw6TpEERM+9NFytGa5FnoHWVxItIwt8hfU8r1Nq9c5q0bWm3D5HiOlMHEibvpLW73BsJ9De4POZQGgIBCQ8H62aiOyJhYiYOBN5cy9ArzUZ8bTpp7OhFY6ublSU7kbD6RPoiaR9pqOsiEpJRBplm1WXHUQn5Q/UxXehxtSMdFcu5maWYOrEGThyuA7xiTmYVjgZzfVVyMxMRWQCbaND6dalu/YjI3sqcvNn0LoeB1paOmnn6wY0VlbB2d0DW5wNtZ2tmHXBYlTRlj0XFl4YGiojWIoyDjVS+62NtPBoLawNpGuUFhBbOIHQ43OZwPARCEh4vv51EVLz5sCRVIi86RcgJj4bX//tE/TXViOLLJ7Opib6mo4d7RG0UWMKJQ5MnoD603U4eWQ/YrKcaI5por2nG1CQkIcMigOZLYXo60+g+MxMRFnj4CBrJjcrjtbx0JY59h5s3VmKBSXn0ycUJlPMpxcx5gQc3rMPRw8fQUpmGiJTozH/vLPR2NeBxs4mzM8qGT5SZ6jkcNlvLZyEZygbiQo7Vld1OFGUYuGU6TM0hvk2TECPQEDCU/bmPNoxugix069E+qRzKa36MPZu/gw22k06rr8FyTExqKyvQWQm7TBgJhEppO10qqrRWHccBRPtOFp/AJHpQH5aOg5uJwnqmIKkzFm47Mqr0NxI8QlaipFEq8ztvS2IphTpqroWnLX4fEoqiKHdrjvg6jDhxNGTOHriOKYunIWZS+bTzgi0ZsjRh3ZaAzQ3/1y99vJxJsAEmAATGGECAQlP1TsL0WmheEvmuUgi4Wlq7cbmj9+FpWk/JsV1IyU+gr4u2oGUycXopV0F2um7PJVV/0B67GnEkxFUR+KSWgCkU7Larh20uLAGyMg/C+dccDEqG+iLo3YKCiXSglNaNBpJ+71RihvyJxbTd3gmkksvFeVHq7Fz1wFUNTfjrIvORlZ+Btrbmihp24QYqwXFRRePME6+PRNgAkyACegRCEh4Sp+fBksGxVvyaA1NEq2/oXU45bu/QlznIcxO70RDxUcQMpptSQvR6kxGVUMbcjMqkWKqhKkWJFRA9nSgvFzMmu4ibemlLLfExOmwR+aizZqII20NSKQdCQqTptMWO8LuBnG09U4KMnKm4EhZBbbsPYBpM+bSPm9UhtmJKFpimhYVhfIjx3D5DQ/otZePMwEmwASYwAgTCEh4Nv10OpxJZGVMK0FzCn14LD6O4jvH4Tz1FSZZ9yDe3EZb3ZAlc5w2nI5PQE9vLmIdB7GY9gztIbE5cAyYcg5QQ2nUtCQHsblANAkQLe1BTGYKuhOLsbW6CQ31FhSmLcSiWUvQ1dyFOEqnjs3Iw5cU39lx8Cgu+cYVbqsohjZqy0uIw8mDpThy4BD+35MvjjBOvj0TYAJMgAnoEQhMeH52BcVwDsJ60Q3omTQVO8p2ofHUJ5gWV4YpZIFMSwVZIKBPJAANDRTLyV6CjtoTOF1aCydlRqdMBbopxpOUTR8gJYGipDj3Bp/tVbRhDlk/UxbeiP31HahvcSAlKhvTJhQhgr5YarUmIXtKMb7acxC7DpRhGqVeZ8YkoogWsDYdP4Y/vvESZi1YguUPPqPXXj7OBJgAE2ACI0wgIOHZSwtI9299C33zaIeCGfSZA/pMdcWh9ZgUW4MS+jpBNH0AknQGx/dTLCeekgUopnNgE21LT9uzCZ/dKf4GucSieiB8DSWTdrixJE1FX7cFls4oJMVMcAvM9kMHsPvATlxyyc1YPG8RThwpRzKlW8+cVYJde8uwdfsBFJIIxUbYUFwwETXlh/CX917HxTfcgaXfvnuEcfLtmQATYAJMQI9AQMJTfeRrvPrCLYidtwTTLzyPdhogZWncixR7KZJ6j4L2+MTeXUBaHCUSnAL2C6JDlkxEp3tfUEy7PAcHI+rRF3k2ic4c7KmupN2pE2mHHCtmFcRjUrYDp45tw6ED25GTNxtTpxYjm1xsrg4HpuXMQkd1LxprOjBxwjQykWjj0e462um6HpUVB3H2dx5E/vT5eu31Ot6/83e4da3n89fCQWvu5XjuyUuQ5XVmDd5Z9Us0X/tfuCewWwRUn6GfPFrqOfSWcglMgAmMXgIBCY/QzHdeuwl582fQFmrxcNBam8xIJ1pP74CjcTvioypwguI4Tvo0ShVZPnZyr9nqyMUmfBiSYjrdRWk4nrOQPu52DiUH5KOevrdjt6SgvqYH/e2HMDWzC+bWw+jv6kL2hOlw9LeSiEXRjgR5iOqNQaw9jRaOuhAbbUV6dgLaeupp4WglyqqqcPMTvw2gF8QJeoPpSh+RkcRo2X3PyUQmPCd0oa53bJwga0N41jOAjuFTmQATGAcEAhaeEyffQ3xqC33dsR9dnQ6YnWacOroH9Se34qxZWXD0VOAA7WBw6iQlDFgSkNzchpgWiuPQf+V56aiZcxeyshbD3tZH6dUn0RsRj7ziElRXHyRxOY0ZlJbd0dZFadtJ9JlrWhPUdRoLC0joumIRbcqExWUHbWCN7rYTlM/WhrLTp5C16Fqcc+1Kw921ad2D+DDnp3jqKgo4qfwcVX/FQ6tKsWz1Q7jS/YHT8JzQWXgMdzmfyASYQBgRCFh4+h2taOn7CxkwsfS9HdqngD5N0N/Tjv6WCqDlOHppV+kDe77CAcpsy8k1IaXFBRslD4C+cl2XtRB1RTfBlpmB1rpydFcepe/pZCO68FyygBzoqTmCkrR4nDzdhEZrClJim9FXtQ2zc3KwbNE30FTbhU2bPqfPZDdTNlwP7QXnIsGqx93PbKTPbVOKnIGfcrI++f4zeGgjZULQ77ySuajLudwtSMK/P1FzNV5dOUtFeEQherd6IR5dtxyz3UL1ESqET6jSz9tdJ57bdM330bX2d9hiWuC+pmtA/Fa6Xhq8v9LNJwqgermCeP5qm+ermdGLvkd1TRNdgtc8iuQNz+CPVWaqURZWDAiocM2LppUDbRJhCe18bEcJXif3Iv+YABNgAmeCQMDCI1SqpfNr9Padhstig4u+mWOmvYxtfd2I6mxBU3kZtnz9GY5UbEMv5VanutJgqqlFRL8TDebZOG2eCVeGCX195YisrUREzhJEn3Uj+ikIVH9yPybaXDh4ohF98QWYNT0OPdU7Ed3ViPNnL4al34xjR/ahvr6CUqwjkJyciMkzLsKy6+8zzEpu7UiTrhjT8bZqhEn/kRcj8OPVvseEMtZUXT3o4jr5/qvYt/B2L+vog7w7vURrGxbgontuGzgHkISj8JpHBiwv8f6e6wRR8FcuJWxouNrercrxEhuprqnsmjM8TvhEJsAEho9AUMLjcvWgsfY9fLV5C9ImTCHLpgCVxyoQQ6tBO2l7grbOBrQ4W7D9+A50dvWiqb4WCZH9SLAW0Afe6KNu5E5zdB9BFn1vp85Ma4MKr0VvJO1SnW6lcrfhOFk88anzUTg1BW3VpaR09ZiZnY+MiDgkkNgdO0RuOdpqWFgzdOMDP0N0nPAFUyM/YXJfj9h7HiYBkP9ZvFYQg9KS/3bHdrSEZ/Y2b9FRu6u3IIiCsrfkMS/Xnpr14evi8y5dKTRawiO/l1Dmw6sacNtvlmMeduP5lR+jaMAC8j5mhB+fwwSYABMYOoGghEe4bX3tfjz73EOYNW8BfabaBmcfuXU6Tag5WYm6pmo4YsgVlmxHC2hz0P5upKYnknOOzqGYTxp93761+TR9OiEOzY6J6I2aiz5XKtLTYxBtO4T9h8vR3J2Gs84uISE6hq6GU5iekoCE7l4sKpiGtlPk1KLdq4uW3YhC+gaQ8Z8/4fEWImFSv4tcUHJX21bk4HR1tttVNk9xU7nLTjjkcZupx4fU40zewiCUo12utsUjz75TipnS4vO4E41T5DOZABNgAkMhELTwCDf95JMNtFP0TtisEcjLzkMl7URdVVmLXmcnfcKaPtqW0I/K3ma02WgPNxKdlroyRDvr6HMIRdi7/yAlFriQO3EO0hNmo6suCV21jSjMqEdFcw0O1Doxs2QpmluaUUtZc8WUB5DcehIzY1OR1m9H2qxzULLivwNuu8eq8RYE72w2pViIf3cLD8WrpJiJeHNBLNZjR+4Vg643NYtHmYqtLzx65QYnPFLdnn1yFr4aFSniAXcxX8AEmECYExiS8Ahte239Gmwv/RKZuemISSHXGW3gmZiRSB9H6EFkvAs1XXXocJmxd+8p2GkH6Txyp6WlTcHJStonx9qO3Lw0+rdcdNZn4eA/jyPTXovoJBsaLbFIpM8cuOgDcPv2bMDMiR1IbNuEs9OnY8qkCzH/1rVBoZVbMvLgvRCcf2nhtsF1PVrp1JdVPIOHN0YMio+au8pf7EiqtJqrTajb8hesgwkLHheZeJV3ucEJjyiUH2PKvXPw5dr6ARdcUCj5IibABJhAUASGLDzCXV/Z8Dx9o6eFPlHgoj3YLKinz1J3O3rR1tWC6vpTyMidQtvodCImIhJxlL3mpK+KushKcqGO3GsOJEZbUFcZj0Ob6e89wKT8JDTQIiBr9FkwmTNx6NCHmJRZjWzrLlyy8B5cdP0LQTVWvCiY1GjvawQBePj9CbKMNk/qtSRmtYMWkLarTchK8wicaOE0UUaakFWndJH5lisKjyRUouvP915qcSNB9P5UmYf6vMu9MtyGAJUvZQJMgAkYJhAS4RHu9vGJ36PBchhlR8to9+lq5E6bjtrmJrj6I5GWSpuFJiahhayho6V7kZU3jSwiO6oaS2lNTxRsvZ2UqUbiU26HtSEaJbMTaJHpMdScngiLfQrs9mokx53CNy/4JpZevNpw47RPFCf5PYu+7zPxblpH6chX/WQw+0xLrKSsNEE4BCtISskWYju/+FYFHtmYN+B68xPjyb4Lc7b/1p32LPzElGghfVv8yeM7vuV6hEa43iudWrbDgprw6CUxhAAwF8EEmAAT0CQQMuER7nCg9Qu8/PlDJDIp6KTNPTvtVmQnzaQNPzOQPjEJ5RXHUHHyBGKi4ikluxXVbaeRnZXu/nR2T58JdVWtqD3cRt/gAfLyaTucqtmw2ovh6unAbdffhKVnXxvSrlQG7tUm/5DeUFaY3iLW4bqvUK5vNtxw3o3LZgJMgAl4Ewip8AhFt9POoLvaN+KocyvKT1G8B5MxNXsmmmgHgurGE0hMi6XdDWjXg94+7D9ZTh95y4e9tg39rj50dLfSJxI6aTucKPTYaRFpeQquXbgSN154NZLiaKfRMfQbOeFRT+8eQ2i5KUyACYQ5gZALj9TeDorRHOvYg7KGHTBZe9FPiz/bOmrRTZ/INsXaUE9WTsspSjbImkiLSXtgd7nQ0lqP7s5a+kz2TBRnXITzJtMnthO9t+sMc56GqzcSwiO5B5UuPcOV5hOZABNgAiEgMGzCI69bY88JtPbXop5ca5X0mew6SxN9EyECGa1x9LnsZLS7HBTDyUU06Ls7iQXIoS+S8o8JMAEmwATGJoEzIjxjEx23igkwASbABIIhwMITDDW+hgkwASbABIImwMITNDq+kAkwASbABIIhwMITDDW+hgkwASbABIImwMITNDq+kAkwASbABIIhwMITDDW+hgkwASbABIImwMITNDq+kAkwASbABIIhwMITDDW+hgkwASbABIImwMITNDq+kJzaQ68AABfpSURBVAkwASbABIIhwMITDDW+hgkwASbABIImwMITNDq+kAkwASbABIIhwMITDDW+hgkwASbABIImwMITNDq+kAkwASbABIIhwMITDDW+hgkwASbABIImwMITNDq+kAkwASbABIIhwMITDDW+hgkwASbABIImwMITNDq+kAkwASbABIIhwMITDDW+hgkwASbABIImwMITNDq+kAkwASbABIIhwMITDDW+hgkwASbABIImMCzC89ot8fiZeT2Ovn5d0BXTunA4yw55ZblAJkAEhDH7k2OP4vNtj6HoDBDpfecm5DwQjVfrXsFVZ+B+o/UW9n1PYMHFL2HJ2iqsu2E0tGIfHlt4MTZf+w989rgwksS//6F4naG5NpzGRUDCIzxAP/gkXrOH0i5d4wYwnOIQ6rK1OiPU9xGhKQfOaBjsXMehEmDhGSrB4bl+qMLjwtu4Ie2H+MxkUlSwAI99sQkPzQh1vcep8Mgxip32CW5TATw8k7Z491CXzcIT6oeDyxtpAuH0ZjvSLIbz/pLwND/49wELZDjvNvQX13AaFwFZPCw8Qx1YbPEMlSBfr08gnCYY/dqO3jNYeILvu2EVnn3XvIWs+78arN2NKr5UufvObLpU1y8tWTxGypZM6dODNZCbwKIIrD1lldErwI9fvgzv3PkCPNcA0QUPyPzz3td5HwN8zW/xnj/Yd5MXC+GmkmvSt/s8AvWs8yYs+5+6gVPUTHjt+ggTUNb9p73MfjX3glTn1BeqVX3dEvODj+5y+8QlNvN/8LnXm5503tuFq911lrNRc0uojQexzp4xM/cHa3DOe3d7+bG17lOo4vqQ30Oy0pf//WW0rLhgsO/FdvR7jQdl30iT+St1V+CVtAcH3StC+S/e4O1y0eIixTyNj2HvvhWejzVrenHvfSf9unLUhGfn6nmycaQc0x5PgpHnSlnW9f/7P2i5935Ib/5a40mtXkr3vdozYWRMCA+I8nlX9oPyOVPz2ijbpv2Mep51fxaP8b4G9Lj6uup9X2S15h/B7ac1hv21MXhp8X/lsAmPEAuSN0jogB9++m2ZsIjQXjH/aHBSF8B/Y808v+IjDVT/ZUudGOP1gIod6/1vgbjapE7d+83/HQzmefvvfQfCztW34tMbXx/w9xq1eDwTjufh8eWlVx9pIpYLijS45fz03pCFNv746Czkma7GmwMBcukhT5OJj3TelKKH8bUssUSaOOQiYPTftPpbqI/yPkLbXpi5e1A8lcLrmZg8Ai6Nifz841j0SI37WjVxluorfzkS6zYb+fku3Lr+a3cfq4m90j1sbAz79rda/dUeb2V/CuPkOyVleGowucE3KG2sTmrPle9YNSo8QnvOf2b+4FhRsyDUxolaXZXnGbFGlMKjxu27t9rwpkaSlJF7hJKrvvD4n3/UxrAa3+ESG3m5wyY83iLjeTuQJkG1B9RI8N1XwHzL9jcglJNAIMKjJozyh+x/i7XjXiL0wIRHLsrC1UpmevVZd4P6BPMX03X45BPzoMAL5dx0ZJVmZowac6E+yvurn6edeSNcf9VfvjPw4qHORktcleNL/WHxLlNNLNXKF8pSGyeCJeZrQb0Eufiq9bGa8CjrrxQ7rXGp9vKkbLvei4Q0luSZb2p9p6yTlqAouRoVHrU+C25MqI8xPQ5K4Qk0fqyVXCC39EPJVU94/MXdPfOH9xhWG+ujWniU6aNKMdDK9NHrfLXrlGWri5qIUzlZGhcerQlUPrmJ7poXT1+pYbUFJjyetEmx7t4TgZH6FLnbK03uogX0Kyz+4sfYcuFzWPKl8JauXyetvlJ7cJX97i9zSN5PP3Jqpbaqi6dWerLaZCBZjeoPpnr7jbygqE+wvuWpCY9yuYHR58Pf2JYmDP+iJbltAaX1plcnrXsr6x6o8CjdbdLEPUUz3dl7TGiNMb2JWM3iEV4u9Fx0EmejFk+ouOoJj3Rca/7R6j+t53s4BWjYLB492MrBJm+kP5+jmjCpCY/WOgblQxmo8HjHhDy1VrrExPOUMRn9Sd6fZaQmPHr1kT9cQpxp0n/OdVsYW8lN9LsZ2/Hp47vdYiSKkPpQ03oZMPLG6O/hlx8ThUctS1JdeNTWiUljymOVqFk8ynuEr/CotTEY4ZHGTYMsVqkc90N5roIVHsnNI3/e5S9KovDojwnfWK58HGunNquNTalOQgl6sY9QCo/afOVbvnKsqo1deVzQu+3+5rozuc5MYDuiwhPMIlOjD4gyqC4NxaFaPEorxN9bgd5EqH2t+mSoJjz69RHLani0Hue/K4qNsPhMcq8JwWRJjLQWN2oJj5HJKzCLR3+S0XINGLFmjJwj9Uk4WDyhEh61/jPSd0Zf6IITHvUxHrzwqC/t8Pd86r8UvQS5WCvLCk/h8dRSOf+w8NDEp+d/1RowRoRHy9RXm7SMWzyim84TkzBiiBp5Q1Erx4jwGK+PwGyV6VHcfHgjkl/b7LZshIdu4dJTuPaBUrxx+Kd+Vz5rxXiUJrq6QGlbeb5uwB8OZkYp3RnKhA7lpKw2iShjD6NJeLQSbYKJ8aj1i7JPjTxX/l1a8liXtqh4koe039al2KaUHKPMGvONyxn1JHg/a3quOL05KlTCEzxXvXZ7H2fhkW33oAygv3ZLCWoe3xaQ20dtAKg9oGoPs9bgUxMZ9UA0de5Z/4lztr+Ky2gy//6fb8V6d/vUs6P0YljGXW2epAr5pOz28w7UR9ouRXIfaKU3q6U1yx9R6c1JmQmnDLb7s4yU56q5jHz7zOM2UGYx6rlyJX+34IocjTEetbHmcQP5XxmvnGDUrHyhPwKN8UgvbvLECHlMTR4bUd5TmlwrZUsmlC8uUsalfJwaHRNq2VnCPeVZc8pXPOWz//tbbkPSm68NbjOkF/sIlfAY5+r/RVZoj7/5h4VnYGKWTw7SoNDzqxp5M5PKkvtrhX9TrrmRu1XErYA8D7T8gdJbj+I9sXnWuQjlKyd1uT/ayDoecU8m8af2ZuQvmO7PalAb7HpWprQ+RzzPd/LzJ6pKP7zWmi3vtQwFeHRgzY18Pyo9gZPa8e21nyHjmfMH97YaTRaP0AZl3wrjRVxn4702S9lvvhOM3O8vPgcfPrwXy+6PGkyCCeS5ksdnhX6U1jZ5Wyb691RrnzDGlF4FI2NCYKB83tXGqJyVWoxSviWY1nyhfK58t8zxPPeh5aovPPJ1dsr5Z0wIj9Ykxf8+9ggYs9KGq9167oThum94lqvn/hmJWvtzbQ9PfcbHmDjzXIent9RKDTq54MxVke800gRGUnj8JSeMNJeRuL+e+2ck6mQk0y6U9RovY+JMcw1lH+mVxcKjR4iPh3xjVi2kyp0H1GNq46NDhLZ77zagvhvHmaahjMEqEzhCXZ/xMibONNdQ91Og5bHwBEpsHJ5/piweXx89DC/mG3vd4h0jEdpnZC/D4ebgHW8R76aXnDKUOo2XMXGmuQ6lT0JxLQtPKChyGUyACTABJmCYAAuPYVR8IhNgAkyACYSCAAtPKChyGUyACTABJmCYAAuPYVR8IhNgAkyACYSCAAtPKChyGUyACTABJmCYAAuPYVR8IhNgAkyACYSCAAtPKChyGUyACTABJmCYAAuPYVR8IhNgAkyACYSCAAtPKChyGUyACTABJmCYQBgJTx+eeNmOGdfH4OZkw/WXnShc34fopXF4dFIw1/M1TIAJMAEmcCYIBCA8Drzyxy680mryqVdEUiR+920rJgypxkMVniHdPIQXj5V2hBAJF8UEmAATkBEIQHjk3IZjch2OMkeir8dKO0aCHd+TCTCB8UAgRMIjTrZFF1vwt8/7UTVgAeUc78Kyz52DHL+pcIP9/dN2PFkuWlDF823I2CW52pSTt+9k7n1tLF5Y0C9z1anXx9si8z7nlLsWEfj3O6Nwjqzn5fdRWnYOr/ZF4KnrTVj3p36IZdEHtyZF4/+WWsbDOOI2MgEmwAQMEwih8PRhk5fLzYH1nzpw8TKb2wUnTtLmwYn9xI4OrCz3uOiEv39vtxn/4o7x+Bce72sd+Oq4CedPtiuER1kfJRMxJiSvs1qd5HUUROiXppgBMRGud+IyhVABbPEYHn18IhNgAuOSQAiFRy8xQD4hq03O/o7rXSv0nZFz5H0caB2ke0hioyUwLDzj8kniRjMBJmCYwLAKj2jFyOsit2iU1kIgwqNnaRiZ/NXOoQSKd3sQtTR2wOryV0dJiPrwJf3R40Y0cm/D/cMnMgEmwATGHIFhEx7BtfbNXVZZtpueRRKI8KhZV3rlq7nalOXI3WdaFlEoRG/MjSNuEBNgAkzAMIEzJjzeMRzAO14i/v3JcstAjEdM3d48OY6SBkzwf61WjMeI668P22QJAGp1eqolalA8lcc9lMX6Vi+MpzVEbPEYHn18IhNgAuOSwLAJD6UTeK378c5aE1h7H//m0ih0f9Y3uIBUnjGmf62waDQ4i2faPBNe3u1wd77aeiTtrDYxOUFwswm/4vlCZp2YoSe5GDmrbVw+U9xoJsAEdAgEKTxjgStbJmOhF7kNTIAJjD4CLDxBb9Ez+jqba8wEmAATCAcCLDwsPOEwDrkOTIAJjCMC41h4xlEvc1OZABNgAmFEgIUnjDqDq8IEmAATGA8EWHjGQy9zG5kAE2ACYUSAhSeMOoOrwgSYABMYDwRYeMZDL3MbmQATYAJhRICFJ4w6g6vCBJgAExgPBFh4xkMvcxuZABNgAmFEgIUnjDqDq8IEmAATGA8EWHjGQy9zG5kAE2ACYUSAhSeMOoOrwgSYABMYDwRYeMZDL3MbmQATYAJhRICFJ4w6g6vCBJgAExgPBFh4xkMvcxuZABNgAmFEgIUnjDqDq8IEmAATGA8EWHjGQy9zG5kAE2ACYUSAhSeMOoOrwgSYABMYDwRYeMZDL3MbmQATYAJhRICFJ4w6g6vCBJgAExgPBFh4xkMvcxuZABNgAmFEgIUnjDqDq8IEmAATGA8EghCeGryz6pf4Y5XZzSd60ffw6spZOqzEa5qv/S/cM1/91P6dv8PytQ1YsfohXJkz+tEL7bl17b7BhvjjFO5tN9KWTesexK+2Rbjba829HM89eQmyBlqvd73yeOE1j+Cpq9JH/yDgFjABJqBKIEDhEQXkg7w7B8RG+Xffe8gnpGX3PachPGI571bljBHhqcG760px7t3fGJh8d+P5levRdM2jKhNquLddvy0n338Gj+0oGRAb3zGix2LTuvWIuXsF5rmHj8gq9r7nNV9SjD3LJ/Dryxdg1fZoXPL0Fvzh7gk+l/V98iNk3vK2anFq17jwMR5IvQ1vmMWXLuU58vIizCvwp9pf4Hyf0r1f3NSE2lj7hu8sR9Vf8ciLEfjxas/LQ6juFu4vWaFqJ5fjn0BAwiMMyIdXNeC23ywfmCQAtX+TbukeZC9Y8ci6Wfjcz2QiTFyPV+dh3rYaFI0Ri0eJ3Xty9hwdjW33bouvUAhj4qFVpVim0ZdaLCQqwsvKi6aVBixp7cEtF4HhEp7ERT/Hlx/ciYkD1fjgXy1Y/lqm+296wuOx/vVf3s70JDacwnOm28L3C08CAQmPJCSPrvMIj/iG+rFbMC6D1oSj/RYrCdfy3wjiJJaj5WoTJqQPc36Kla6X8NDGBjdRpVvHH2b39dl3Yc723w66CgUr7K5Mod4foQImmEzz4d2+0HScwO6OjRO8XFCBtF2ohTBhS+02kS3lcUsOuDLJokre8Iy7bd7HxTZoXx9YG+VtSVd5GdGzWtRYyGsg9XOw7jY9y0SrtdJ1Hyx52ktQpPOl429aFuGsszZj+/YleH7LRtwxCZCObVhcgqKt27HXcrtfi0fudtbjEVjvDP1sFp6hM+QS/BMISHjUrRuPqIgTuNqbrpbwyGM/HgHzJzxCHMETAwjsbVGY0P57W97ghC1NxB7xCqy8QAaX71t8YG1XWgneLwG+7jrhfmuqrh4UOv/XB9ISQN4W9UnTf0zPn0Wj/nITWP0Ey+O231+JFbc58Or6XZquNmWpksVy/9tVeGqp7z0lcXkn4g7cunwNlR0/WLZkYZ27Yjm6X31tiMIjPi+b6fVB+Hlc1MK/78PF7pc08bjvC8h6RF4zF1+s/RsqTQsGXqK83Xu+L2ve97vwW5ehfLtpwNUm3nOpzMsh9NFd5Fr1xHa9y/e8vPn+u+j9kJfnr27CMXLD3nMZjqx6RWyvz4uhFivFi9YwvVAGNjL5bIlAQMID+E7MUgxHO34j3EpdeLwnIGPCo3TB6Ll1lG/S3tf71ms43j6FSf/h9yd4WVKBtV2NjXxyF/+8t+SxwRiS90uC3vXGHwhlW/wJj7w+0h3UWEjjQ5hYArFg1Wp96IVLcfbj+9yC8HPnnYN/VovxyK93nFiLS0t+hrLFT6laO8K5cuF5440+fOfmt5B7+xvY9+xFkMTul29ehbduWhWA8CjHoLIv5X0nnrtlUFAAtReQDaYrZZa17zOrFpOT95X3S4ue8KiV/xGar55LYvELWTxYEIKP0HR1hkx4jNXt3eqFg8+O93OjzUrwvsjDAvade7FvwZzBEIHxEc9nDgeBAIXHIyLS29jSe+9A19q/6sRmjEzwxoRHcLV5u2D0r5PA+bpwfK81KjxGBc9tZW0v8RId33v4b4My60s+EETB97Uw5PW7tMY7w873emNDy1hbhLLULR6165V3Fuv9EWJUEzHEmKJW/EiyOiQxkIuQnvBI1o5WPEgpPO/WLsPblGggWD/SnwUX3af/04e7ScD0XG1SVqjSJao2/jzjtnLQre3xCvi+gMjdeOpeCtGSiL3nYbd7XC1u60ku8C88WhaqtuXqKW+2qpvWU7crc+R/FkeK3A2YquK+llitXrDDb5zR2Ijns4aLQBDC410Vf8kFnjPV3+qkh0/ZOK3UY3Xff7gKj5bbzjerSd5+tbbru5/0hUdI8gg+dqXtgtSO+8kz0wJzYfprrz/h+fXlye4sNrWfJEZqx+SxGylm4+88QWyEjLW2gWSCu55ajZ3/9gRS/n0r3vrGX9yWk57wSOKgdDtqvWSI7mVBeLzdXkI9Pc+FY1BQJGHStkhF4RFeStRij4EIj/J6oU7aL3Ae4ZmpIhziS4tYNyPCI1+yIPWZ5IqXXmKE2K1/j8xwTa9crhaBIQuPYLY/UXO1TgaSkRRZfQFRiw3oT8qepofS4tEbUoFlZvlvu7515V94tJM+9FohHvffFt+6K19GAmOhdB8Zq6NwVrDCI1lKyiw15Z3lrjZBeBbL0rFNprPciQa3QXTZGRUepRvav8Wt5zL1tRDUnw/PeYLwKF9KvOugb/EMRXh8X4gCEx61e/uOGCPzj/FxxmcOncCQhEeZk689QRrpeGPCIyQXeAdbPetj9CboQIVHyNjylxashV+vHuoPhn5Gn7fLTr6+xr/wCG+/vm4uz/X+2mmkLd4xAW+/u/71u/Hn93Nx3dXSglFxrKiveQpswBt1tRlxswl3VgrPebJ1PZJo5Q7EiowLj1Jo/bVfPLZn0fcHX/R84zWStSCxUo+jeF4WlfcTz/fEiZRxFGV5vvX1xHK8+9FojMdTN/+utqyB2LHaWBHmpt+avjewFkzd9RvYaOKzQ0kgQOHxdhMpM0zOhPAo06Hlrim9Se7MCo+Ynq38qZv8+qIrWR7S7gDC35XZfUrfvlI0pUQQqU7eLgn1dTdyd4W/tsjL9u0Tfyx8XY+h2rlAKTzq6dKehaZa2WxSu5XCIywOVYqWlKQQiPBIfevJQhQncymO6nnOROvjvHvteHZtqbta3s+g70Qt1t27PGUCh7yPhZjTd++dg39ssAwuIFUev+lbGdhQs1Dm5dAq3/ffn30yDW96uQv91U1PeHzbJvEQ4kfSEgnhLGM7rIRyauWy/BEIUHhGFuZQ13eMbO357iNNQHKp+UsgGOk6+r+/r9srvOvLtWMC6gRYeHhkjBsCggV0zhNRg4s+R1/DWXhGX59xjdUIsPDwuGACo4YAC8+o6SquqF8Co0p4uC+ZABNgAkxg9BNg4Rn9fcgtYAJMgAmMKgIsPKOqu7iyTIAJMIHRT4CFZ/T3IbeACTABJjCqCLDwjKru4soyASbABEY/ARae0d+H3AImwASYwKgiwMIzqrqLK8sEmAATGP0EWHhGfx9yC5gAE2ACo4oAC8+o6i6uLBNgAkxg9BNg4Rn9fcgtYAJMgAmMKgL/H8GaNG3TDm7cAAAAAElFTkSuQmCC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuEZ3XVcSyc5"
      },
      "source": [
        "### Some principles for creating effective prompts\n",
        "\n",
        "1. Be clear and detailed\n",
        "2. Explicitly ask for an output format\n",
        "3. Give the model a \"role\"/\"persona\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhkbWWUP0T5m"
      },
      "source": [
        "## Task 1: Structuring unstructured data\n",
        "\n",
        "Can we extract the most relevant characters discussed in a news article using an LLM?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2DnH9lauJ7Y"
      },
      "outputs": [],
      "source": [
        "# https://www.newyorker.com/news/the-lede/donald-trump-wins-a-second-term\n",
        "\n",
        "# load the data with utf-8 encoding\n",
        "\n",
        "with open('./example_text.txt', 'r', encoding=\"utf-8\") as file:\n",
        "    ny_article = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezkOml7tuJ7Z"
      },
      "outputs": [],
      "source": [
        "# print part of text\n",
        "\n",
        "print(ny_article[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnHrjsPMuJ7a"
      },
      "outputs": [],
      "source": [
        "# PRINCIPLE 1: Be clear and detailed (BAD PROMPT)\n",
        "my_prompt = f\"\"\"\n",
        "whom does this article talk about?:\n",
        "\n",
        "{ny_article}\n",
        "\"\"\"\n",
        "\n",
        "print(my_prompt[:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDBYf4LrbDx7"
      },
      "outputs": [],
      "source": [
        "# re-start the client\n",
        "client = OpenAI(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byWLE5qJuJ7b"
      },
      "outputs": [],
      "source": [
        "# get a response from the model\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-0125\",    # name of the model,\n",
        "    messages=[\n",
        "        {\"role\": \"user\",\n",
        "         \"content\": my_prompt},\n",
        "    ],\n",
        "    max_tokens=100,                 # max number of tokens to generate\n",
        "    temperature=0.0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-gWWHu8uJ7b"
      },
      "outputs": [],
      "source": [
        "# extract response\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWtHxEFzuJ7b"
      },
      "outputs": [],
      "source": [
        "# PRINCIPLE 1: Be clear and detailed (GOOD PROMPT)\n",
        "my_prompt = f\"\"\"\n",
        "We want to extract the relevant people from a news article.\n",
        "\n",
        "Please follow these steps:\n",
        "1. Identify all the people mentioned and any description of them\n",
        "2. Identify any political offices mentioned\n",
        "\n",
        "Here is the text of the article:\n",
        "{ny_article}\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIkq2P8ruJ7b"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-0125\",    # name of the model,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": my_prompt},\n",
        "    ],\n",
        "    max_tokens=1000,                 # max number of tokens to be generate\n",
        "    temperature=0.0                 # temperature\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mq-Wm0v0uJ7b"
      },
      "outputs": [],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUp5moc8uJ7b"
      },
      "outputs": [],
      "source": [
        "# PRINCIPLE 2: Explicitly ask for an output format\n",
        "\n",
        "my_prompt = f\"\"\"\n",
        "We want to extract the relevant characters from a news article. Provide your output in json format with each step as a key.\n",
        "\n",
        "Please follow these steps:\n",
        "1. People: Identify all the people mentioned and any description of them\n",
        "2. Institutions: Identify all the institutions mentioned\n",
        "\n",
        "Here is the text of the article:\n",
        "{ny_article}\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSuRMyNHuJ7b"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-0125\",    # name of the model,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": my_prompt},\n",
        "    ],\n",
        "    max_tokens=1000,                 # max number of tokens to be generate\n",
        "    temperature=0.0                 # temperature\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keih8tf5uJ7b"
      },
      "outputs": [],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cO0IX6KSuJ7b"
      },
      "outputs": [],
      "source": [
        "# https://www.texastribune.org/2024/09/18/texas-venezuelan-gang-tren-de-aragua-abbott-crackdown/\n",
        "\n",
        "# load the data with utf-8 encoding\n",
        "\n",
        "with open('./example_text2.txt', 'r', encoding=\"utf-8\") as file:\n",
        "    tt_article = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgUMVz7huJ7c"
      },
      "outputs": [],
      "source": [
        "# PRINCIPLE 3: Give the model a role/persona\n",
        "my_prompt = f\"\"\"Summarize the article below.\n",
        "Article:\n",
        "{tt_article}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guBgLXTMoX8J"
      },
      "source": [
        "We will give the model its role/person through a **system prompt**. Anthropic provides a nice [guide](https://docs.anthropic.com/en/docs/system-prompts) explaining what system prompts are and how to use them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvoeMDjlatU5"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-0125\",    # name of the model,,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that replies with a concise one-sentence answer that always starts with the letter T.\"},  # define the ROLE/PERSONA\n",
        "        {\"role\": \"user\", \"content\": my_prompt},\n",
        "    ],\n",
        "    max_tokens=100,                 # max number of tokens to be generate\n",
        "    temperature=0.0                 # temperature\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiRVW5ksuJ7c"
      },
      "outputs": [],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fR4_YNWcsEd4"
      },
      "outputs": [],
      "source": [
        "# Under-the-hood the \"system prompt\" is partially how the models have certain guardrails\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-0125\",    # name of the model,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"\"\"You are a language model that works with young children. Never produce content related to violence or gangs.\"\n",
        "        If asked to produce this content please reply with the phrase \"I can't do that :( \\nViolence is not good  \" \"\"\"\n",
        "        },\n",
        "        {\"role\": \"user\", \"content\": my_prompt},\n",
        "    ],\n",
        "    max_tokens=100,                 # max number of tokens to be generate\n",
        "    temperature=0.0                 # temperature\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQtqqQa33DWQ"
      },
      "outputs": [],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zdi3DzyCuJ7c"
      },
      "source": [
        "## Task 2: Latent Concept Detection\n",
        "\n",
        "To demonstrate this task we will use data from [The Voice of Monetary Policy (Gorodnichenko  et. al 2023)](https://www.aeaweb.org/articles?id=10.1257/aer.20220129) paper that contains labeled sentences from press conferences after FOMC meetings. Sentences were labeled as hawisk, neutral or dovish."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwI9IYDpUydI"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-0125\",    # name of the model,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"\"\"You are an expert financial analyst with great capacity to explain complex concepts to a broad audicence.\"\"\"},\n",
        "        {\"role\": \"user\", \"content\": \"Explain the meaning of hawkish and dovish\"},\n",
        "    ],\n",
        "    max_tokens=200,                 # max number of tokens to be generate\n",
        "    temperature=0.0                 # temperature\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnKBW20qVIjT"
      },
      "outputs": [],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWDfF7Y8uJ7c"
      },
      "outputs": [],
      "source": [
        "file_id = \"1INq3wr9DuykD4iSlUCocHegOJ5qgLP8z\"\n",
        "df = pd.read_csv(f\"https://drive.google.com/uc?export=download&id={file_id}&authuser=0&export=download\", sep=\"\\t\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWv04lzVdXGl"
      },
      "outputs": [],
      "source": [
        "# explore a sentence and its label\n",
        "i = np.random.randint(0, len(df))\n",
        "print(\"Label: \", df.loc[i, \"sentiment\"], \"\\n\\n\")\n",
        "print(df.loc[i, \"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLtLxXkauJ7c"
      },
      "outputs": [],
      "source": [
        "# first attempt at a prompt\n",
        "def generation_prompt(text):\n",
        "    prompt = f\"\"\"\n",
        "    Classify the following text as hawkish, dovish, or neutral.\n",
        "\n",
        "    Text: {text}\n",
        "    \"\"\"\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAtRGVFRuJ7c"
      },
      "outputs": [],
      "source": [
        "i = 1184\n",
        "print(\"Label: \", df.loc[i, \"sentiment\"])\n",
        "text = df.loc[i, \"text\"]\n",
        "my_prompt = generation_prompt(text)\n",
        "print(my_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-K9qHjUJbOmR"
      },
      "outputs": [],
      "source": [
        "# re-start the client\n",
        "client = OpenAI(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLIU9g9RuJ7c"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-0125\",    # name of the model\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": my_prompt},\n",
        "    ],\n",
        "    max_tokens=10,                  # max number of tokens to be generate\n",
        "    temperature=0.0                 # temperature\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T01KoFKWuJ7d"
      },
      "outputs": [],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WfDatNG_uJ7d"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "display(HTML(\"\"\"\n",
        "<div class=\"alert\">\n",
        "  <h2> Exercise </h2>\n",
        "  <br>\n",
        "  <p> 1. Improving the prompt </p>\n",
        "  <br>\n",
        "  <ol type=\"a\">\n",
        "  <li> Expand the current prompt in a way that helps generate better results.</li>\n",
        "  <li> What principles or ideas did you use? </li>\n",
        "  <li> Try your new prompt. Any improvements? </li>\n",
        "  </ol>\n",
        "  <br>\n",
        "\n",
        "</div>\n",
        "\n",
        "<style>\n",
        ".alert {\n",
        "  padding: 20px;\n",
        "  background-color: #586BA4;\n",
        "  color: white;\n",
        "  margin-bottom: 15px;\n",
        "}\n",
        "\n",
        "h2{\n",
        "  font-size: 30px;\n",
        "  color: white;\n",
        "}\n",
        "\n",
        "li, p{\n",
        "  font-size: 20px;\n",
        "}\n",
        "\n",
        "</style>\n",
        "\"\"\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ynKXhJpmGHg"
      },
      "outputs": [],
      "source": [
        "# Modify the function\n",
        "def generation_prompt(text):\n",
        "    prompt = f\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    YOUR WONDERFUL NEW PROMPT\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    {text}\n",
        "    \"\"\"\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z10CmWofmGFa"
      },
      "outputs": [],
      "source": [
        "# generate text from the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSW5v7EamGCL"
      },
      "outputs": [],
      "source": [
        "# print response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3fD1NOhomF5t"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "display(HTML(\"\"\"\n",
        "<div class=\"alert\">\n",
        "  <h2> DON'T GO BEYOND THIS POINT ON YOUR OWN </h2>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "</div>\n",
        "\n",
        "<style>\n",
        ".alert {\n",
        "  padding: 20px;\n",
        "  background-color: #F49D37;\n",
        "  color: white;\n",
        "  margin-bottom: 20px;\n",
        "}\n",
        "\n",
        "h2{\n",
        "  font-size: 50px;\n",
        "  color: white;\n",
        "}\n",
        "\n",
        "li, p{\n",
        "  font-size: 20px;\n",
        "}\n",
        "\n",
        "</style>\n",
        "\"\"\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQeptQPPuJ7d"
      },
      "outputs": [],
      "source": [
        "# Source of inspiration for the prompt:\n",
        "# https://www.newyorkfed.org/medialibrary/media/research/conference/2023/FinTech/400pm_Hansen_Paper_Kazinnik_2023.pdf?sc_lang=en&hash=9B1647BD6876D0F3959C6919BA3F82DE\n",
        "\n",
        "def generation_prompt(text):\n",
        "    prompt = f\"\"\"\n",
        "    Your task is to classify the text into one of the three categories (\"dovish\", \"neutral\", \"hawkish\").\n",
        "    The text is taken at random from the texts of FOMC announcements.\n",
        "    Provide your output in json format with a key \"category\" and the selected category.\n",
        "\n",
        "    Text:\n",
        "    {text}\n",
        "    \"\"\"\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nW3cI8Y7uJ7d"
      },
      "outputs": [],
      "source": [
        "#i = np.random.randint(0, len(df))\n",
        "i = 1184\n",
        "text = df.loc[i, \"text\"]\n",
        "sentiment = df.loc[i, \"sentiment\"]\n",
        "my_prompt = generation_prompt(text)\n",
        "print(\"Human label for sentiment: \", sentiment)\n",
        "print(my_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrdTl15EuJ7d"
      },
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo-0125\",    # name of the model\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a research assistant working for the Fed. You have a degree in Economics.\"},\n",
        "        {\"role\": \"user\", \"content\": my_prompt},\n",
        "    ],\n",
        "    max_tokens=15,                 # max number of tokens to be generate\n",
        "    temperature=0                  # temperature\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hgkb76HsuJ7d"
      },
      "outputs": [],
      "source": [
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nK8tvrhuJ7e"
      },
      "source": [
        "### Estimating the cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQJo6uc3uJ7e"
      },
      "outputs": [],
      "source": [
        "# To get the tokeniser corresponding to a specific model in the OpenAI API:\n",
        "cost_per_million_input = 0.5\n",
        "cost_per_million_output = 1.5\n",
        "\n",
        "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo-0125\")\n",
        "\n",
        "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "def calculate_cost(input_tokens, output_tokens, input_cost, output_cost):\n",
        "    return (input_tokens/1000000)*input_cost + (output_tokens/1000000)*output_cost\n",
        "\n",
        "\n",
        "prompt = \"\"\"You are a research assistant working for the Fed. You have a degree in Economics.\n",
        "Your task is to classify the text into one of the three categories (\"dovish\", \"neutral\", \"hawkish\").\n",
        "The text is taken at random from the texts of FOMC announcements.\n",
        "Provide your output in json format with a key \"category\" and the selected category.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRUNemM9uJ7e"
      },
      "outputs": [],
      "source": [
        "all_costs = []\n",
        "for text in df[\"text\"].values:\n",
        "    all_text = prompt + text\n",
        "    num_tokens_input = num_tokens_from_string(all_text, \"gpt-3.5-turbo\")\n",
        "    num_tokens_output = 15\n",
        "    cost = calculate_cost(num_tokens_input, num_tokens_output,\n",
        "                          cost_per_million_input, cost_per_million_output)\n",
        "    all_costs.append(cost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUcV-FqQuJ7e"
      },
      "outputs": [],
      "source": [
        "df[\"cost\"] = all_costs\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2m0bpPeduJ7f"
      },
      "outputs": [],
      "source": [
        "print(f\"Total cost of processing the data: {np.round(df['cost'].sum(), 3)} USD\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly3NjVHcuJ7f"
      },
      "source": [
        "### Running the model on many texts\n",
        "\n",
        "Some resources on how to run many prompts:\n",
        "\n",
        "- [Batch processing](https://cookbook.openai.com/examples/batch_processing)\n",
        "- [Rate limits](https://platform.openai.com/docs/guides/rate-limits/error-mitigation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1zbdtexuJ7f"
      },
      "outputs": [],
      "source": [
        "def classify_response(result):\n",
        "    if \"hawkish\" in result:\n",
        "        return \"hawkish\"\n",
        "    elif \"dovish\" in result:\n",
        "        return \"dovish\"\n",
        "    elif \"neutral\" in result:\n",
        "        return \"neutral\"\n",
        "    else:\n",
        "        return np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyauT-UKuJ7f"
      },
      "outputs": [],
      "source": [
        "# # DON'T RUN!\n",
        "# all_responses = []\n",
        "# for text in tqdm(df[\"text\"]):\n",
        "#     my_prompt = generation_prompt(text)\n",
        "#     response = client.chat.completions.create(\n",
        "#         model=\"gpt-3.5-turbo-0125\",    # name of the model,\n",
        "#         messages=[\n",
        "#             {\"role\": \"system\", \"content\": \"You are a research assistant working for the Fed. You have a degree in Economics.\"},\n",
        "#             {\"role\": \"user\", \"content\": my_prompt},\n",
        "#         ],\n",
        "#         max_tokens=15,               # max number of tokens to be generate\n",
        "#         temperature=0                # temperature\n",
        "#     )\n",
        "#     result = response.choices[0].message.content\n",
        "#     all_responses.append(classify_response(result))\n",
        "\n",
        "# # append data to existing dataframe\n",
        "# df[\"gpt_response\"] = all_responses\n",
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Qe2djAf6n4r"
      },
      "outputs": [],
      "source": [
        "# read data after doing GPT classification\n",
        "file_id = \"1v6U80WISF4TxXTLPBvTpiV8iWlIgNsHG\"\n",
        "df = pd.read_csv(f\"https://drive.google.com/uc?export=download&id={file_id}&authuser=0&export=download\", sep=\",\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZnIQapkq93b"
      },
      "outputs": [],
      "source": [
        "# calculate accuracy\n",
        "df[\"gpt_correct\"] = df[\"sentiment\"] == df[\"gpt_response\"]\n",
        "gpt_accuracy = df[\"gpt_correct\"].mean()\n",
        "print(f\"Random guessing accuracy: {1/3}\")\n",
        "print(f\"Accuracy of GPT: {gpt_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9nP9bxFdgks"
      },
      "source": [
        "# 3. Getting embeddings from the API\n",
        "\n",
        "[OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sgEV1Rld78U"
      },
      "outputs": [],
      "source": [
        "# initialize a client using the API key\n",
        "client = OpenAI(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2DUDdh2dtTx"
      },
      "outputs": [],
      "source": [
        "text = \"This is a small test to get some embeddings.\"\n",
        "result = client.embeddings.create(input = [text],\n",
        "                                  model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jY6yiklleGh_"
      },
      "outputs": [],
      "source": [
        "embeddings = result.data[0].embedding\n",
        "len(embeddings)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}